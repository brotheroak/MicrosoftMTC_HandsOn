{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-getting-started.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import requests\n",
        "import tempfile\n",
        "import azureml.core\n",
        "from azureml.core import Workspace, Experiment, Datastore, Environment\n",
        "# from azureml.widgets import RunDetails\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.core import Experiment\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "env = Environment.get(workspace=ws, name=\"automl-nasa-test2\")\n",
        "\n",
        "# Enable Docker\n",
        "docker_config = DockerConfiguration(use_docker=True)\n",
        "\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
        "\n",
        "\n",
        "experiment_name = 'train-on-nasaexperiment'\n",
        "experiment = Experiment(workspace = ws, name = experiment_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.38.0\nmlprojecta\nparta-projecta\nkoreacentral\ne6ec79e7-c7e5-4312-85d0-75e8285c09dd\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1647493235376
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "aml_compute_target1 = \"cpu-cluster-automl\"\n",
        "try:\n",
        "    aml_compute1 = AmlCompute(ws, aml_compute_target1)\n",
        "    print(\"found existing compute target.\")\n",
        "except ComputeTargetException:\n",
        "    print(\"creating new compute target\")\n",
        "    \n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
        "                                                                min_nodes = 1, \n",
        "                                                                max_nodes = 4)    \n",
        "    aml_compute1 = ComputeTarget.create(ws, aml_compute_target1, provisioning_config)\n",
        "    aml_compute1.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "    \n",
        "print(\"Azure Machine Learning Compute attached\")\n",
        "\n",
        "aml_compute_target2 = \"cpu-cluster-custom\"\n",
        "try:\n",
        "    aml_compute2 = AmlCompute(ws, aml_compute_target2)\n",
        "    print(\"found existing compute target.\")\n",
        "except ComputeTargetException:\n",
        "    print(\"creating new compute target\")\n",
        "    \n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
        "                                                                min_nodes = 1, \n",
        "                                                                max_nodes = 4)    \n",
        "    aml_compute2 = ComputeTarget.create(ws, aml_compute_target2, provisioning_config)\n",
        "    aml_compute2.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "    \n",
        "print(\"Azure Machine Learning Compute attached\")\n"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1647491285852
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a RunConfiguration to specify some additional requirements for this step.\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
        "\n",
        "# create a new runconfig object\n",
        "run_config = RunConfiguration()\n",
        "\n",
        "# enable Docker \n",
        "run_config.environment.docker.enabled = True\n",
        "\n",
        "# set Docker base image to the default CPU-based image\n",
        "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
        "\n",
        "# use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
        "run_config.environment.python.user_managed_dependencies = False\n",
        "\n",
        "# specify CondaDependencies obj\n",
        "run_config.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn', 'pandas', 'numpy', 'azure'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647491288955
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "# Uses default values for PythonScriptStep construct.\n",
        "\n",
        "source_directory = './scripts'\n",
        "print('Source directory for the step is {}.'.format(os.path.realpath(source_directory)))\n",
        "\n",
        "os.makedirs(source_directory, exist_ok=True)\n",
        "shutil.copy('../nasa_forecast/helper.py', source_directory)\n",
        "\n",
        "# step1 = PythonScriptStep(name=\"Auto ML\",\n",
        "#                          script_name=\"auto-ml-forecasting-nasa.py\", \n",
        "#                          compute_target=aml_compute1, \n",
        "#                          source_directory=source_directory,\n",
        "#                          runconfig=run_config,\n",
        "#                          allow_reuse=False)\n",
        "src1 = ScriptRunConfig(source_directory=source_directory, \n",
        "                      script='auto-ml-forecasting-nasa.py', \n",
        "                      compute_target=aml_compute1, \n",
        "                      environment=env,\n",
        "                      docker_runtime_config=docker_config)\n",
        " \n",
        "run1 = experiment.submit(config=src1)\n",
        "\n",
        "# All steps use the same Azure Machine Learning compute target as well\n",
        "# step2 = PythonScriptStep(name=\"Custom ML\",\n",
        "#                          script_name=\"custom-ml-forecasting-nasa.py\", \n",
        "#                          compute_target=aml_compute2, \n",
        "#                          source_directory=source_directory,\n",
        "#                          runconfig=run_config,\n",
        "#                          allow_reuse=False)\n",
        "src2 = ScriptRunConfig(source_directory=source_directory, \n",
        "                      script='custom-ml-forecasting-nasa.py', \n",
        "                      compute_target=aml_compute2, \n",
        "                      environment=env,\n",
        "                      docker_runtime_config=docker_config)\n",
        "\n",
        "run2 = experiment.submit(config=src2) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1647491305782
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of steps to run\n",
        "steps = [step1, step2]\n",
        "print(\"Step lists created\")\n",
        "\n",
        "pipeline1 = Pipeline(workspace=ws, steps=steps)\n",
        "print (\"Pipeline is built\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'step1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9ea81556d6f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# list of steps to run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstep1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step lists created\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpipeline1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'step1' is not defined"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647485843327
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline1.validate()\n",
        "print(\"Pipeline validation complete\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1647485843618
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run1 = Experiment(ws, 'TimeSeriesMetric').submit(pipeline1, regenerate_outputs=False)\n",
        "print(\"Pipeline is submitted for execution\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1647485845304
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(pipeline_run1).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1647485845719
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "order_index": 1,
    "exclude_from_index": false,
    "task": "Getting Started notebook for ANML Pipelines",
    "deployment": [
      "None"
    ],
    "authors": [
      {
        "name": "sanpil"
      }
    ],
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "compute": [
      "AML Compute"
    ],
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "tags": [
      "None"
    ],
    "datasets": [
      "Custom"
    ],
    "categories": [
      "how-to-use-azureml",
      "machine-learning-pipelines",
      "intro-to-pipelines"
    ],
    "category": "tutorial",
    "framework": [
      "Azure ML"
    ],
    "friendly_name": "Getting Started with Azure Machine Learning Pipelines",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}